{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import dill\n",
    "import autograd.numpy as np\n",
    "from autograd import grad \n",
    "import random\n",
    "import types\n",
    "import warnings\n",
    "from copy import deepcopy\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load defined models and trajectories\n",
    "'''\n",
    "These are synthetics examples for an optimal stopping problem for\n",
    "clinician diagnosis of disease\n",
    "'''\n",
    "with open('data/model0.obj', 'rb') as f:\n",
    "    model = dill.load(f)\n",
    "with open('data/model0_trajs.obj', 'rb') as f:\n",
    "    trajs = dill.load(f)\n",
    "    trajs = random.sample(trajs, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Set the dimensions of the spaces\n",
    "'''\n",
    "\n",
    "s_size = model.S #2\n",
    "a_size = model.A #3\n",
    "z_size = model.Z #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random initialisation of params\n",
    "model.b0 = np.random.dirichlet([1]*model.S)\n",
    "model.O = np.random.dirichlet([1]*model.Z, size=(model.A,model.S))\n",
    "model.mu = np.random.normal(.5,.5, size=(model.A,model.S))\n",
    "\n",
    "model.T = model.T.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Softmax functions to parameterise distributions so that we don't have to \n",
    "do constrained optimisations\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def softmax_O(x):    \n",
    "    e_x = np.exp(x - np.max(x,axis=2).reshape((a_size,s_size,1)))\n",
    "\n",
    "    return e_x / e_x.sum(axis=2).reshape((a_size,s_size,1))\n",
    "\n",
    "def softmax_b0(x):    \n",
    "    e_x = np.exp(x - np.max(x))\n",
    "\n",
    "    return e_x / e_x.sum(axis=0)\n",
    "\n",
    "def softmax_T(x):    \n",
    "    e_x = np.exp(x - np.max(x,axis=2).reshape((s_size,a_size,1)))\n",
    "\n",
    "    return e_x / e_x.sum(axis=2).reshape((s_size,a_size,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "like = np.array([-np.inf] * 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Define mean vector policy parameterisation - this is original DIPOLE we\n",
    "will use to generate a warm start for our parameters\n",
    "'''\n",
    "\n",
    "def policy(mu,eta,b):\n",
    "    del_a = np.exp(-eta*np.sum((b-mu)**2,axis=-1))\n",
    "    del_a /= del_a.sum()\n",
    "    return del_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This is just to initialise some of the latent variables\n",
    "'''            \n",
    "    \n",
    "for traj in trajs:\n",
    "    traj.alp = [np.zeros(model.b0.shape) for _ in range(traj.tau+1)]\n",
    "    traj.alp[0] = model.b0.copy()\n",
    "    for t in range(traj.tau):\n",
    "        traj.alp[t+1] = np.ravel(model.O[traj.a[t],:,traj.z[t],np.newaxis] * model.T[:,traj.a[t],:].T @ traj.alp[t][:,np.newaxis])\n",
    "    traj.bet = [np.ones(model.b0.shape) for _ in range(traj.tau+1)]\n",
    "\n",
    "    for t in reversed(range(traj.tau)):\n",
    "        traj.bet[t] = np.ravel(model.T[:,traj.a[t],:] @ (model.O[traj.a[t],:,traj.z[t],np.newaxis] * traj.bet[t+1][:,np.newaxis]))\n",
    "    traj.gmm = [alp * bet for alp, bet in zip(traj.alp, traj.bet)]\n",
    "    traj.gmm = [gmm / gmm.sum() for gmm in traj.gmm]\n",
    "    traj.xi = [None] * traj.tau\n",
    "        \n",
    "    for t in range(traj.tau):\n",
    "        traj.xi[t] = model.O[traj.a[t],:,traj.z[t],np.newaxis].T * model.T[:,traj.a[t],:] * (traj.alp[t][:,np.newaxis] @ traj.bet[t+1][:,np.newaxis].T)\n",
    "        traj.xi[t] /= traj.xi[t].sum()\n",
    "    traj.b = [alp / alp.sum() for alp in traj.alp]\n",
    "\n",
    "like[1:] = like[:-1]\n",
    "like[0] = 0\n",
    "like_a = 0\n",
    "for traj in trajs:\n",
    "    like[0] += np.sum(traj.gmm[0] * np.log(np.clip(model.b0, 1e-100,None)))\n",
    "    for t in range(traj.tau):\n",
    "        like[0] += np.sum(traj.xi[t] * np.log(np.clip(model.T[:,traj.a[t],:], 1e-100,None)))\n",
    "    for t in range(traj.tau):\n",
    "        like[0] += np.sum(traj.gmm[t+1] * np.log(np.clip(model.O[traj.a[t],:,traj.z[t]], 1e-100,None)))\n",
    "    for t in range(traj.tau):\n",
    "        like[0] += np.log(np.clip(model.pi(traj.b[t])[traj.a[t]], 1e-100,None))\n",
    "        like_a += np.log(np.clip(model.pi(traj.b[t])[traj.a[t]], 1e-100,None))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Key likelihood function, what we're looking to optimise, define here, optimsise later\n",
    "'''\n",
    "\n",
    "def likelihood(params,trajs):\n",
    "    \n",
    "    b0  = softmax_b0(params[0])\n",
    "    O   = softmax_O(params[1])\n",
    "    T   = softmax_T(params[2]) \n",
    "    mu  = params[3]\n",
    "    eta = params[4]\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    First we gnerate beliefs\n",
    "    '''\n",
    "    for traj in trajs:\n",
    "        traj.alp1 = [np.zeros(b0.shape) for _ in range(traj.tau+1)]\n",
    "        traj.alp1[0] = b0\n",
    "        for t in range(traj.tau):\n",
    "            traj.alp1[t+1] = np.ravel(O[traj.a[t],:,traj.z[t],np.newaxis] * T[:,traj.a[t],:].T @ traj.alp1[t][:,np.newaxis])\n",
    "\n",
    "        traj.b = [alp / alp.sum() for alp in traj.alp1]\n",
    "    \n",
    "    likes = 0\n",
    "\n",
    "    '''\n",
    "    Now calculate the likelihood\n",
    "    '''\n",
    "    like_a = 0\n",
    "    for traj in trajs:\n",
    "        likes += np.sum(traj.gmm[0] * np.log(b0))\n",
    "        for t in range(traj.tau):\n",
    "            likes += np.sum(traj.xi[t] * np.log(T[:,traj.a[t],:]))\n",
    "        for t in range(traj.tau):\n",
    "            likes += np.sum(traj.gmm[t+1] * np.log(O[traj.a[t],:,traj.z[t]]))\n",
    "        for t in range(traj.tau):\n",
    "            likes += np.log(policy(mu,eta,traj.b[t])[traj.a[t]])\n",
    "            like_a += np.log(policy(mu,eta,traj.b[t])[traj.a[t]])\n",
    "    return likes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Collect parameters to be optimised\n",
    "'''\n",
    "par = [model.b0,model.O,model.T,model.mu,float(model.eta)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood(par,trajs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Main training loop for the warm start\n",
    "'''\n",
    "\n",
    "\n",
    "l_rate = 1e-3\n",
    "\n",
    "liks = []\n",
    "param_history = []\n",
    "\n",
    "grad_p = grad(likelihood)\n",
    "\n",
    "\n",
    "for itr in tqdm(range(1000)):\n",
    "    \n",
    "    par = [model.b0,model.O,model.T,model.mu,float(model.eta)]\n",
    "    param_history.append(par)\n",
    "    \n",
    "    b0  = softmax_b0(model.b0)\n",
    "    O   = softmax_O(model.O)\n",
    "    T   = softmax_T(model.T) \n",
    "    '''\n",
    "    Forward-Backward algorithm to fix latent variables\n",
    "    '''\n",
    "    for traj in trajs:\n",
    "        traj.alp = [np.zeros(model.b0.shape) for _ in range(traj.tau+1)]\n",
    "        traj.alp[0] = b0.copy()\n",
    "        for t in range(traj.tau):\n",
    "            traj.alp[t+1] = np.ravel(O[traj.a[t],:,traj.z[t],np.newaxis] * T[:,traj.a[t],:].T @ traj.alp[t][:,np.newaxis])\n",
    "        \n",
    "        traj.bet = [np.ones(model.b0.shape) for _ in range(traj.tau+1)]\n",
    "        for t in reversed(range(traj.tau)):\n",
    "            traj.bet[t] = np.ravel(T[:,traj.a[t],:] @ (O[traj.a[t],:,traj.z[t],np.newaxis] * traj.bet[t+1][:,np.newaxis]))\n",
    "        traj.gmm = [alp * bet for alp, bet in zip(traj.alp, traj.bet)]\n",
    "        traj.gmm = [gmm / gmm.sum() for gmm in traj.gmm]\n",
    "        \n",
    "        traj.xi = [None] * traj.tau\n",
    "        for t in range(traj.tau):\n",
    "            traj.xi[t] = O[traj.a[t],:,traj.z[t],np.newaxis].T * T[:,traj.a[t],:] * (traj.alp[t][:,np.newaxis] @ traj.bet[t+1][:,np.newaxis].T)\n",
    "            traj.xi[t] /= traj.xi[t].sum()\n",
    "            \n",
    "        traj.b = [alp / alp.sum() for alp in traj.alp]\n",
    "    '''\n",
    "    Now call gradient and unpack\n",
    "    '''\n",
    "    grads = grad_p(par,trajs)\n",
    "    \n",
    "    model.b0  += l_rate * grads[0]\n",
    "    \n",
    "    model.O   += l_rate * grads[1]\n",
    "\n",
    "    model.T   += l_rate * grads[2] \n",
    "    model.mu  += l_rate * grads[3]\n",
    "    model.eta += l_rate * grads[4]\n",
    "    lik = likelihood(par,trajs)\n",
    "    print(lik)\n",
    "    liks.append(lik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(liks)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('warm_model.obj', 'wb') as f:\n",
    "    dill.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Now generate belief-action pairs so we can train the soft tree on them\n",
    "first as a warm-start\n",
    "'''\n",
    "\n",
    "belief_list = []\n",
    "action_list = []\n",
    "for traj in trajs:\n",
    "    a = deepcopy(traj.a)\n",
    "    action_list += a\n",
    "    b = deepcopy(traj.b)\n",
    "    belief_list += b[:-1]\n",
    "    \n",
    "beliefs = np.array(belief_list)\n",
    "beliefs_1 = beliefs[:,0].reshape(370,1)\n",
    "action_list = np.array(action_list)  \n",
    "actions = np.zeros((370,3))\n",
    "actions[:,0] = action_list == 0\n",
    "actions[:,1] = action_list == 1\n",
    "actions[:,2] = action_list == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from soft_tree_model import soft_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_tree = soft_tree(tree_depth = 3,xdim=s_size,ydim=a_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(policy_tree.params)):\n",
    "    policy_tree.params[i] = policy_tree.params[i] * 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Now get warm start parameters\n",
    "'''\n",
    "policy_tree.train(beliefs,actions,100,l_rate = 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood_tree(params,trajs):\n",
    "    \n",
    "    b0  = softmax_b0(params[0])\n",
    "    O   = softmax_O(params[1])\n",
    "    T   = softmax_T(params[2]) \n",
    "    \n",
    "    tree_p = params[3]\n",
    "    \n",
    "    for traj in trajs:\n",
    "        traj.alp1 = [np.zeros(b0.shape) for _ in range(traj.tau+1)]\n",
    "        traj.alp1[0] = b0\n",
    "        for t in range(traj.tau):\n",
    "            traj.alp1[t+1] = np.ravel(O[traj.a[t],:,traj.z[t],np.newaxis] * T[:,traj.a[t],:].T @ traj.alp1[t][:,np.newaxis])\n",
    "\n",
    "        traj.b = [alp / alp.sum() for alp in traj.alp1]\n",
    "    \n",
    "    likes = 0\n",
    "      \n",
    "    like_a = 0\n",
    "    for traj in trajs:\n",
    "        likes += np.sum(traj.gmm[0] * np.log(b0))\n",
    "        for t in range(traj.tau):\n",
    "            likes += np.sum(traj.xi[t] * np.log(T[:,traj.a[t],:]))\n",
    "        for t in range(traj.tau):\n",
    "            likes += np.sum(traj.gmm[t+1] * np.log(O[traj.a[t],:,traj.z[t]]))\n",
    "        for t in range(traj.tau):\n",
    "            likes += np.log(policy_tree.forward([traj.b[t]],tree_p).reshape(3)[traj.a[t]])\n",
    "            like_a += np.log(policy_tree.forward([traj.b[t]],tree_p).reshape(3)[traj.a[t]])\n",
    "    return -likes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par = [model.b0,model.O,model.T,policy_tree.params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Main training loop for InterPoLe\n",
    "'''\n",
    "\n",
    "\n",
    "l_rate = 1e-3\n",
    "\n",
    "liks = []\n",
    "param_history = []\n",
    "\n",
    "grad_p = grad(likelihood_tree)\n",
    "\n",
    "\n",
    "for itr in tqdm(range(100)):\n",
    "    \n",
    "    par = [model.b0,model.O,model.T,policy_tree.params]\n",
    "    param_history.append(par)\n",
    "    \n",
    "    b0  = softmax_b0(model.b0)\n",
    "    O   = softmax_O(model.O)\n",
    "    T   = softmax_T(model.T) \n",
    "    \n",
    "    for traj in trajs:\n",
    "        traj.alp = [np.zeros(model.b0.shape) for _ in range(traj.tau+1)]\n",
    "        traj.alp[0] = b0.copy()\n",
    "        for t in range(traj.tau):\n",
    "            traj.alp[t+1] = np.ravel(O[traj.a[t],:,traj.z[t],np.newaxis] * T[:,traj.a[t],:].T @ traj.alp[t][:,np.newaxis])\n",
    "        \n",
    "        traj.bet = [np.ones(model.b0.shape) for _ in range(traj.tau+1)]\n",
    "        for t in reversed(range(traj.tau)):\n",
    "            traj.bet[t] = np.ravel(T[:,traj.a[t],:] @ (O[traj.a[t],:,traj.z[t],np.newaxis] * traj.bet[t+1][:,np.newaxis]))\n",
    "        traj.gmm = [alp * bet for alp, bet in zip(traj.alp, traj.bet)]\n",
    "        traj.gmm = [gmm / gmm.sum() for gmm in traj.gmm]\n",
    "        \n",
    "        traj.xi = [None] * traj.tau\n",
    "        for t in range(traj.tau):\n",
    "            traj.xi[t] = O[traj.a[t],:,traj.z[t],np.newaxis].T * T[:,traj.a[t],:] * (traj.alp[t][:,np.newaxis] @ traj.bet[t+1][:,np.newaxis].T)\n",
    "            traj.xi[t] /= traj.xi[t].sum()\n",
    "            \n",
    "        traj.b = [alp / alp.sum() for alp in traj.alp]\n",
    "        \n",
    "    grads = grad_p(par,trajs)\n",
    "    \n",
    "    model.b0  -= l_rate * grads[0]\n",
    "    \n",
    "    model.O   -= l_rate * grads[1]\n",
    "\n",
    "    model.T   -= l_rate * grads[2] \n",
    "        \n",
    "    policy_tree.params = policy_tree.update_step(policy_tree.params,grads[3],l_rate)\n",
    "    \n",
    "    lik = likelihood_tree(par,trajs)\n",
    "    print(lik)\n",
    "    liks.append(lik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('interpole_model.obj', 'wb') as f:\n",
    "    dill.dump(model, f)\n",
    "    \n",
    "with open('interpole_tree.obj', 'wb') as f:\n",
    "    dill.dump(policy_tree, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
